{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import numpy as np\n",
    "from scipy.misc import imread\n",
    "from scipy.misc import imsave\n",
    "from scipy.misc import imshow\n",
    "from scipy.misc import imresize\n",
    "import cv2\n",
    "\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')\n",
    "\n",
    "import import_ipynb\n",
    "import Nets as nets\n",
    "import Gans as gans\n",
    "\n",
    "import sys\n",
    "sys.path.insert(0, os.path.abspath('./CyclicGen/'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "def run_gan_cfg(f,s):\n",
    "    cv2.imwrite('first.png', f)\n",
    "    cv2.imwrite('second.png', s)\n",
    "    ##%run CyclicGen/CyclicGen_train_stage1.py --pretrained_model_checkpoint_path=./ckpt/CyclicGen/model --subset=test --batch_size=1\n",
    "    ##print(\"test ended ok!\")\n",
    "    #%run CyclicGen/run.py ##--pretrained_model_checkpoint_path=./ckpt/CyclicGen/model --first=./first.png --second=./second.png --out=./out.png\n",
    "    session = gans.get_model(f.shape[0],f.shape[1])\n",
    "    print(\"test run_gan_cfg ended ok!\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "def load_vid(vid_path):\n",
    "    print(\"Loading:\", vid_path)\n",
    "    cap = cv2.VideoCapture(vid_path)\n",
    "    num_frames = int(cap.get(cv2.CAP_PROP_FRAME_COUNT))\n",
    "    fps = cap.get(cv2.CAP_PROP_FPS)\n",
    "\n",
    "    vid_arr = np.zeros(shape=(num_frames, 128, 384, 3), dtype=\"uint8\") # 128x384 with 3 color channels\n",
    "\n",
    "    for i in range(num_frames):\n",
    "        #if i % (num_frames / 10) == 0:\n",
    "            #print (\"Video loading is {0}% done.\".format((i / (num_frames / 10) * 10)))\n",
    "\n",
    "        ret, frame = cap.read()\n",
    "        vid_arr[i] = imresize(frame, (128, 384))\n",
    "\n",
    "    ##test\n",
    "    print(num_frames,vid_arr.shape)\n",
    "    return vid_arr, fps"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "## gany python3 run.py --pretrained_model_checkpoint_path=./ckpt/CyclicGen/model --first=./first.png --second=./second.png --out=./out.png"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "def double_vid_fps(vid_arr, method='u_net'):\n",
    "    shps = (6, 128, 384)\n",
    "    #print(shps)\n",
    "    if(method == 'u_net'):\n",
    "        model = nets.get_unet_2(shps) #6 -> 3 chans per frame, 2 frames input\n",
    "        #todo weights\n",
    "        weight_path = \"./deep-motion/model_weights/weights_unet2_finetune_youtube_100epochs.hdf5\"\n",
    "        model.load_weights(weight_path) #weights for trained network\n",
    "        #print(\"weights loaded\")\n",
    "    elif(method == 'gan_cfg'):\n",
    "        session, plch, prediction = gans.get_model(vid_arr[0].shape[0],vid_arr[0].shape[1])\n",
    "    # new_vid_arr = np.zeros(shape=(len(vid_arr)*2, 128, 384, 3))\n",
    "    new_vid_arr = []\n",
    "    new_vid_arr.append(vid_arr[0])\n",
    "    for i in range(1, len(vid_arr)):\n",
    "        if i % (len(vid_arr) / 10) == 0:\n",
    "            print (\"FPS doubling is {0}% done.\".format((i / (len(vid_arr) / 10) * 10)))\n",
    "        \n",
    "        #print(\"predicting\",vid_arr[i-1].shape)\n",
    "        if(method == 'u_net'):\n",
    "            pred = model.predict(np.expand_dims(np.transpose(np.concatenate((vid_arr[i-1], vid_arr[i]), axis=2)/255., (2, 0, 1)), axis=0)) #predict middle frame\n",
    "            new_vid_arr.append((np.transpose(pred[0], (1, 2, 0))*255).astype(\"uint8\")) ##insert middle frame to new_vid_arr\n",
    "        elif(method == 'gan_cfg'):\n",
    "            ## gany python3 run.py --pretrained_model_checkpoint_path=./ckpt/CyclicGen/model --first=./first.png --second=./second.png --out=./out.png\n",
    "            #run_gan_cfg(vid_arr[i-1], vid_arr[i])\n",
    "            pred = gans.gan_pred(vid_arr[i-1], vid_arr[i], session, plch, prediction)\n",
    "            #pred = cv2.imread('./out.png')\n",
    "            new_vid_arr.append(pred) ##insert middle frame to new_vid_arr\n",
    "        else:\n",
    "            print(\"other\")\n",
    "        #new_vid_arr.append((np.transpose(pred[0], (1, 2, 0))*255).astype(\"uint8\")) ##insert middle frame to new_vid_arr\n",
    "        new_vid_arr.append(vid_arr[i]) #insert next frame -> first frame for upcoming prediction\n",
    "\n",
    "    return np.asarray(new_vid_arr)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "def save_vid(vid_arr, vid_out_path, fps):\n",
    "    #todo\n",
    "    fourcc = cv2.VideoWriter_fourcc(*'XVID')\n",
    "    # fourcc = cv2.VideoWriter_fourcc(*'X264')\n",
    "    out = cv2.VideoWriter(vid_out_path, fourcc, fps, (384, 128))\n",
    "\n",
    "    for i in range(len(vid_arr)):\n",
    "        out.write(vid_arr[i])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#makes a collage of output videos (original, subsampled, deepmotion and cyclegan)\n",
    "def combine_vid(original, half, unet, gans, fps_max,fps_n, fps_min,outname, out_dir):\n",
    "    print(original.shape)\n",
    "    f = gans.shape[0]\n",
    "    h_f = half.shape[0]\n",
    "    w = original.shape[2]\n",
    "    h = original.shape[1]\n",
    "    \n",
    "    o_w = w*2+10\n",
    "    o_h = h*2+10\n",
    "    canvas = np.ones((f*2,o_h, o_w,3), dtype=np.uint8)\n",
    "\n",
    "    canvas[0:f,0:h,0:w,:] = original[0:f]\n",
    "    canvas[f:2*f,0:h,0:w,:] = original[0:f]\n",
    "    \n",
    "    #print(f,h_f, f*2 // h_f)\n",
    "    k = 0\n",
    "    for i in range((f*2 // h_f)):\n",
    "        #print(i)\n",
    "        canvas[i*h_f:(i+1)*h_f,h+10:,0:w,:] = half\n",
    "        k=i\n",
    "        \n",
    "    #print((k+1)*h_f, 2*f)\n",
    "    canvas[(k+1)*h_f-1:2*f,h+10:,0:w,:] = half[:(f%h_f):,:,:,:]\n",
    "    canvas[0:unet.shape[0],0:h,w+10:,:] = unet\n",
    "    canvas[unet.shape[0]:unet.shape[0]*2,0:h,w+10:,:] = unet\n",
    "    canvas[0:gans.shape[0],h+10:,w+10:,:] = gans\n",
    "    canvas[gans.shape[0]:gans.shape[0]*2,h+10:,w+10:,:] = gans\n",
    "    \n",
    "    print(canvas.shape, len(canvas), (w,h))\n",
    "    canvas.astype(np.uint8)\n",
    "\n",
    "    # font \n",
    "    font = cv2.FONT_HERSHEY_SIMPLEX  \n",
    "    # fontScale \n",
    "    fontScale = 0.5\n",
    "    # Blue color in BGR \n",
    "    color = (5, 235, 235) \n",
    "    # Line thickness of 2 px \n",
    "    thickness = 1\n",
    "    # Using cv2.putText() method \n",
    "    for i in range(len(canvas)):\n",
    "        canvas[i] = cv2.putText(canvas[i], 'orginal '+str(fps_max)+\" fps\", (20,20), font, fontScale, color, thickness)\n",
    "        canvas[i] = cv2.putText(canvas[i], 'subsampled '+str(fps_min)+\" fps\", (20,h+30), font, fontScale, color, thickness, cv2.LINE_AA)\n",
    "        canvas[i] = cv2.putText(canvas[i], 'U_NET '+str(fps_n)+\" fps\", (w+30,20), font, fontScale, color, thickness, cv2.LINE_AA)\n",
    "        canvas[i] = cv2.putText(canvas[i], 'GAN '+str(fps_n)+\" fps\", (w+30,h+30), font, fontScale, color, thickness, cv2.LINE_AA)\n",
    "\n",
    "    cv2.imwrite(out_dir + outname+\"frame0.png\", canvas[5])\n",
    "    cv2.imwrite(out_dir + outname+\"frame1.png\", canvas[15])\n",
    "    cv2.imwrite(out_dir + outname+\"frame2.png\", canvas[21])\n",
    "    cv2.imwrite(out_dir + outname+\"frame3.png\", canvas[33])\n",
    "    cv2.imwrite(out_dir + outname+\"frame4.png\", canvas[43])\n",
    "    cv2.imwrite(out_dir + outname+\"frame5.png\", canvas[53])    \n",
    "\n",
    "    \n",
    "    fourcc = cv2.VideoWriter_fourcc(*'XVID')\n",
    "    out = cv2.VideoWriter(out_dir + outname+\".mp4\", fourcc, fps_max, (o_w, o_h))\n",
    "    for i in range(len(canvas)):\n",
    "        out.write(canvas[i])\n",
    "    print(\"canvas saved\")\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# combine all output videos into one\n",
    "def combinevid(vids,f, outname, out_dir):\n",
    "    canvas = np.ones((0,266,778,3), dtype=np.uint16)\n",
    "    for vid in vids:\n",
    "        v, fps = load_vid(os.path.join(out_dir, vid))\n",
    "        if(canvas.shape[0] == 0):\n",
    "            canvas = np.ones((len(v),266,778,3), dtype=np.uint16)\n",
    "            canvas = v\n",
    "        else:\n",
    "            canvas = np.concatenate([canvas,v])\n",
    "        \n",
    "    #canvas.astype(np.uint8)\n",
    "    fourcc = cv2.VideoWriter_fourcc(*'XVID')\n",
    "    out = cv2.VideoWriter(out_dir + outname+\".avi\", fourcc, f, (canvas.shape[2], canvas.shape[1]))\n",
    "     \n",
    "    for i in range(len(canvas)):\n",
    "        out.write(canvas[i])"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.9.13 64-bit (windows store)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.13"
  },
  "vscode": {
   "interpreter": {
    "hash": "9da297d614bb2667dfb21fadcf07f5f64679004c9ae9ad9a1b5a03e6f7f19cbc"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
