{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## DDW - Task 2: Index & Document Retrieval\n",
    "\n",
    "První část kódu je věnována nevyužité snaze o úpravu dat pro získání lepších výsledků (čištění dat od zbytečných syntaktických chyb, lematizace, odstranění čísel atp. Věřím že přes zahušťování VSM (vector space model) matice vede cesta k lepším výsledkům..)\n",
    "\n",
    "V druhé části reprezentuji texty ze složky .d (dokumenty) a .q (dotazy) pomocí VSM matic.\n",
    "Na každém typu matice počítám nejrelevantnějších 10 dokumentů. \n",
    "Veškerá finální měření jsou v CSV souboru task2.csv. (Případně úplně dole v 'tab' proměnné.)\n",
    "\n",
    "Komentář k výsledkům: \n",
    "Nepřekvapivě hůř dopadla euklidovská vzdálenost - příznakový prostor má pro tuto vzdálenost příliš mnoho dimenzí (vzdálenosti rostou i pro málo rozdílná data).\n",
    "Z typů reprezentací dokumentů dopadla nejlíp nejsofistikovanější metoda s TF-IDF, v průměru skoro 3x lépe než pouhá pure term frequency reprezentace. TF-IDF narozdíl od pure term bere v potaz data ze všech dostupných dokumentů, tedy lze posoudit i relativní relativitu dokumentů k dotazu v rámci datasetu."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import glob\n",
    "import pandas as pd\n",
    "from sklearn.metrics.pairwise import cosine_similarity, euclidean_distances\n",
    "from sklearn.feature_extraction.text import CountVectorizer, TfidfVectorizer\n",
    "\n",
    "\n",
    "# Reading filenames of all documents\n",
    "all_documents = glob.glob(\"./d/*.txt\")\n",
    "print(\"Number of documents: \"+str(len(all_documents)))\n",
    "\n",
    "# Reading filnames of all queries\n",
    "all_queries = glob.glob(\"./q/*.txt\")\n",
    "print(\"Number of queries: \"+str(len(all_queries)))\n",
    "\n",
    "# Reading filnames of all res\n",
    "all_res = glob.glob(\"./r/*.txt\")\n",
    "print(\"Number of res: \"+str(len(all_res)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def remove_problem_chars(text):\n",
    "    text = text.replace(\".\", \" . \")\n",
    "    text = text.replace(\" .\", \". \")\n",
    "    text = text.replace(\".  \", \". \")\n",
    "    text = text.replace(\".   \", \". \")\n",
    "    text = text.replace(\"+\", \"\")\n",
    "    text = text.replace(\"-\", \"\")\n",
    "    text = text.replace(\"/\", \"\")\n",
    "    text = text.replace(\"\\'\", \" \")\n",
    "    text = text.replace(\",\", \" , \")\n",
    "    text = text.replace(\"=\", \" = \")\n",
    "    text = text.replace(\"'\", \"\")\n",
    "    text = text.replace(\"aa\", \"a\")\n",
    "    return text\n",
    "\n",
    "# Reading all documents to strings and storing them in list \"documents\"\n",
    "documents = []\n",
    "for d in all_documents:\n",
    "    doc = open(d, \"r\")\n",
    "    text = doc.read()\n",
    "    text = remove_problem_chars(text)\n",
    "    documents.append(text)\n",
    "    \n",
    "print(\"First document (content): \\n\"+documents[0]+\"\\n\")\n",
    "print(\"First document (length in words): \"+str(len(documents[0].split(' '))))\n",
    "\n",
    "# Reading all documents to strings and storing them in list \"queries\"\n",
    "queries = []\n",
    "for q in all_queries:\n",
    "    doc = open(q, \"r\")\n",
    "    text = doc.read()\n",
    "    text = remove_problem_chars(text)\n",
    "    queries.append(text)\n",
    "    \n",
    "corpus = documents + queries"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Creating sparse matrix of documents:\n",
    "- each row is one document\n",
    "- each column is word from corpus (combined words from all documents in this case)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# BINARY representation\n",
    "# I am counting out stopwords in effort of reducing the matrix size\n",
    "vect = CountVectorizer(stop_words = 'english',binary = True)\n",
    "X_bin = vect.fit_transform(corpus)\n",
    "\n",
    "# writing matrix into pandas data frame\n",
    "df_freq = pd.DataFrame(X_bin.A, columns=vect.get_feature_names())\n",
    "\n",
    "display(df_freq.iloc[:5,:100])\n",
    "print(df_freq.info())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Even from such a small sample it is obvious that I should further \n",
    "reduce the feature space (number of columns) by lemmatization and even\n",
    "eliminating numbers as they very probaby won't carry much value.\n",
    "Lets try it:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from nltk import word_tokenize          \n",
    "from nltk.stem import WordNetLemmatizer \n",
    "from sklearn.feature_extraction import text \n",
    "import re\n",
    "\n",
    "class LemmaTokenizer(object):\n",
    "    def __init__(self):\n",
    "        self.wnl = WordNetLemmatizer()\n",
    "    def __call__(self, articles):\n",
    "        return [self.wnl.lemmatize(t) for t in word_tokenize(articles)]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# adding other unnecessary characters to stopwords\n",
    "my_added_stopwords = [\"'s\", \"-\", \"+\", \",\", \".\", \"..\", \"(\", \")\", \"/\", \"'\", '\"', \"`\", \"*\", \":\", \"=\", \"?\", \"$\"]\n",
    "stop_words = text.ENGLISH_STOP_WORDS.union(my_added_stopwords)\n",
    "\n",
    "#removing numbers\n",
    "def no_numbers(tokens):\n",
    "    r = re.sub('(\\d)+', '', tokens.lower()) \n",
    "    return r\n",
    "\n",
    "vect = CountVectorizer(tokenizer=LemmaTokenizer(), stop_words = stop_words, binary = True, preprocessor=no_numbers)\n",
    "X_bin = vect.fit_transform(corpus)\n",
    "\n",
    "# writing matrix into pandas data frame\n",
    "df_freq = pd.DataFrame(X_bin.A, columns=vect.get_feature_names())\n",
    "\n",
    "\n",
    "k = 5\n",
    "fe = 20\n",
    "print(\"*BINARY REPRESENTATION*\\nFirst %d documents and first %d words from corpus:\" % (k, fe))\n",
    "display(df_freq.iloc[:k,:fe])\n",
    "print(df_freq.info())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "vect = CountVectorizer(tokenizer=LemmaTokenizer(), stop_words = stop_words, binary = False, preprocessor=no_numbers)\n",
    "X_count = vect.fit_transform(corpus)\n",
    "\n",
    "# writing matrix into pandas data frame\n",
    "df_freq_term = pd.DataFrame(X_count.A, columns=vect.get_feature_names())\n",
    "\n",
    "k = 5\n",
    "fe = 100\n",
    "print(\"*PURE TERM FREQUENCY*\\nFirst %d documents and first %d words from corpus:\" % (k, fe))\n",
    "display(df_freq_term.iloc[:k,:fe])\n",
    "print(df_freq_term.info())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "def getTfIdf(col):\n",
    "    return col.isnull()\n",
    "\n",
    "vect = TfidfVectorizer(tokenizer=LemmaTokenizer(), stop_words = stop_words, preprocessor=no_numbers)\n",
    "X_tfidf = vect.fit_transform(corpus)\n",
    "\n",
    "df_tfidf = pd.DataFrame(X_tfidf.A, columns=vect.get_feature_names())\n",
    "\n",
    "k = 5\n",
    "fe = 30\n",
    "print(\"*TF-IDF FREQUENCY*\\nFirst %d documents and first %d words from corpus:\" % (k, fe))\n",
    "display(df_tfidf.iloc[:k,:fe])\n",
    "print(df_tfidf.info())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Original data for homework task:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "corpus = []\n",
    "for d in range(1400):\n",
    "    f = open(\"./d/\"+str(d+1)+\".txt\")\n",
    "    corpus.append(f.read())\n",
    "# add query to corpus\n",
    "for q in range(225):\n",
    "    f = open(\"./q/\"+str(q+1)+\".txt\")\n",
    "    corpus.append(f.read())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# Vector space model with TF-IDF weighting schema {matrix: #documents x #tokens}\n",
    "vect = TfidfVectorizer()\n",
    "X_tfidf = vect.fit_transform(corpus)\n",
    "\n",
    "# Vector space model - boolean\n",
    "vect = CountVectorizer(binary=True)\n",
    "X_bin = vect.fit_transform(corpus)\n",
    "\n",
    "# Vector space model - pure term frequency -> returns frequency of word in document regardless of other documents\n",
    "vect = CountVectorizer(binary=False)\n",
    "X_count = vect.fit_transform(corpus)\n",
    "\n",
    "\n",
    "# Result data structure for each query = Precision, Recall and F-Measure for each type of term vector\n",
    "result = {\n",
    "    \"query\": 0,\n",
    "    \"tf_idf_cos_precision\": np.nan,\n",
    "    \"tf_idf_cos_recall\": np.nan,\n",
    "    \"tf_idf_cos_fmeasure\": np.nan,\n",
    "    \n",
    "    \"binary_cos_precision\": np.nan,\n",
    "    \"binary_cos_recall\": np.nan,\n",
    "    \"binary_cos_fmeasure\": np.nan,\n",
    "    \n",
    "    \"puretm_cos_precision\": np.nan,\n",
    "    \"puretm_cos_recall\": np.nan,\n",
    "    \"puretm_cos_fmeasure\": np.nan,\n",
    "    \n",
    "    \"tf_idf_eucl_precision\": np.nan,\n",
    "    \"tf_idf_eucl_recall\": np.nan,\n",
    "    \"tf_idf_eucl_fmeasure\": np.nan,\n",
    "    \n",
    "    \"binary_eucl_precision\": np.nan,\n",
    "    \"binary_eucl_recall\": np.nan,\n",
    "    \"binary_eucl_fmeasure\": np.nan,\n",
    "    \n",
    "    \"puretm_eucl_precision\": np.nan,\n",
    "    \"puretm_eucl_recall\": np.nan,\n",
    "    \"puretm_eucl_fmeasure\": np.nan,\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\"\n",
    "Returns 10 most relevant documents [indexes] from d matrix for each query from q matrix\n",
    "Args:\n",
    "        d - document matrix, each row is one term vector 'identifying' one document\n",
    "        q - query matrix, each row is one query term vector\n",
    "\n",
    "Returns:\n",
    "        res - list of vectors of most relevant documents. \n",
    "            There is as many vectors as there are queries in the input q matrix.\n",
    "            Each vector consists of document indexes.\n",
    "\"\"\"\n",
    "\n",
    "# Cosine Based Proximity Measure - 1 if documents are identical (cos(phi) = 0)\n",
    "def get_cosine_similarity(d, q):\n",
    "    sim = np.array(cosine_similarity(q, d))\n",
    "    res = []\n",
    "    for i in range(q.shape[0]):\n",
    "        res.append(sim[i].argsort()[-10:][::-1] + 1)\n",
    "    return res\n",
    "\n",
    "# Euclidean Based Proximity Measure - computes distance in multidim. eucl. space\n",
    "def get_euclidean_similarity(d, q):\n",
    "    euc = np.array(euclidean_distances(q, d))\n",
    "    res = []\n",
    "    for i in range(q.shape[0]):\n",
    "        res.append(euc[i].argsort()[-10:][::-1] + 1)\n",
    "    return res"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "### Reading reference solutions for comparison\n",
    "ref_res = []\n",
    "for q in range(225):\n",
    "    f = open(\"./r/\"+str(q+1)+\".txt\")\n",
    "    text = f.read()\n",
    "    ref_res.append(text.split(\"\\n\")[:-1])\n",
    "    \n",
    "\"\"\"\n",
    "Returns 10 most relevant documents [indexes] from d matrix for each query from q matrix\n",
    "Args:\n",
    "        q - index of query vector {0 to len(all_queries)}\n",
    "        matrix - matrix with term vectors of documents and queries\n",
    "        docs - number of documents -> starting index for queries in matrix\n",
    "\n",
    "Returns:\n",
    "        cos[q], euclid[q] - two vectors of most relevant document indexes for each similarity measure, q is the query index\n",
    "\"\"\"\n",
    "def get_similarities(q, matrix, docs):\n",
    "    queries = matrix[docs:]\n",
    "    #print(queries.shape)\n",
    "    documents = matrix[0:docs]\n",
    "    #cosine\n",
    "    cos = get_cosine_similarity(documents, queries)\n",
    "    #euclidean\n",
    "    euclid = get_euclidean_similarity(documents, queries)\n",
    "    \n",
    "    return cos[q], euclid[q]\n",
    "    \n",
    "    \n",
    "q = 0\n",
    "\n",
    "# list of cos[q], euclid[q] results for each query\n",
    "tfidf_r = []\n",
    "pure_r = []\n",
    "bin_r = []\n",
    "# list of references\n",
    "reference = []\n",
    "\n",
    "# get most relevant documents for each query, term vector type and measure:\n",
    "for q in range(len(all_res)):\n",
    "    if(len(ref_res[q])>0):\n",
    "        ref2 = list(map(int, ref_res[q][:]))\n",
    "    else:\n",
    "        ref2 = []\n",
    "        \n",
    "    reference.append(ref2)\n",
    "    \n",
    "    cos, euclid = get_similarities(q,X_tfidf, len(documents))\n",
    "    tfidf_r.append(cos)\n",
    "    tfidf_r.append(euclid)\n",
    "    \n",
    "    cos_p, euclid_p = get_similarities(q,X_count, len(documents))\n",
    "    pure_r.append(cos_p)\n",
    "    pure_r.append(euclid_p)\n",
    "    \n",
    "    cos_b, euclid_b = get_similarities(q,X_bin, len(documents))\n",
    "    bin_r.append(cos_b)\n",
    "    bin_r.append(euclid_b)\n",
    "    \n",
    "print(len(tfidf_r))\n",
    "print(len(pure_r))\n",
    "print(len(bin_r))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\"\n",
    "Returns number of true positives and false negatives for vector of found solutions \n",
    "Args:\n",
    "        res - vector of found relevant documents\n",
    "        ref - vector of true relevant documents\n",
    "\n",
    "Returns:\n",
    "        true_pos, false_neg - number of true positives and false negatives\n",
    "\"\"\"\n",
    "def getDiagonal(res, ref):\n",
    "    true_pos = 0\n",
    "    false_neg = 0\n",
    "    for doc in ref:\n",
    "        if doc in res:\n",
    "            true_pos += 1 # document is in both datasets\n",
    "        elif doc not in res:\n",
    "            false_neg += 1 # document is in reference but not in my result\n",
    "    return true_pos, false_neg\n",
    "            \n",
    "\"\"\"\n",
    "Returns number of false positives for vector of found solutions \n",
    "Args:\n",
    "        res - vector of found relevant documents\n",
    "        ref - vector of true relevant documents\n",
    "\n",
    "Returns:\n",
    "        false_pos - number of falsely found relevant documents\n",
    "\"\"\"\n",
    "def getFalsePos(res, ref):\n",
    "    false_pos = 0\n",
    "    for doc in res:\n",
    "        if doc not in ref:\n",
    "            false_pos += 1 # document is in my results but not in reference\n",
    "    return false_pos\n",
    "\n",
    "\"\"\"\n",
    "Returns precision for given query retrieval: - ratio of relevant documents to retrieved\n",
    "\"\"\"\n",
    "def getPrecision(true_pos, false_pos):\n",
    "    return (float(true_pos)) / float(true_pos + false_pos)\n",
    "\n",
    "\"\"\"\n",
    "Returns recallfor given query retrieval: - ratio of retrieved documents to relevant {what should have been found}\n",
    "\"\"\"\n",
    "def getRecall(true_pos, false_neg):\n",
    "    return (float(true_pos)) / float(true_pos + false_neg)\n",
    "\n",
    "\"\"\"\n",
    "Returns F-score\n",
    "\"\"\"\n",
    "def getFMeasure(precision, recall):\n",
    "    if(precision == 0.0 or recall == 0.0):\n",
    "        return 0.0\n",
    "    else:\n",
    "        return 2. * ( float(precision*recall) / float(precision + recall) )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "\"\"\"\n",
    "Returns Precision, Recall and F-score for each solution vector\n",
    "Args:\n",
    "        ref - vector of true relevant documents\n",
    "        cos - vector of found relevant documents (cosine sim.)\n",
    "        euc - vector of found relevant documents (eucl. dist)\n",
    "\n",
    "Returns:\n",
    "        result - list of 6 numbers: [ precision_cos, recall_cos, f1_cos, precision_eucl, recall_eucl, f1_eucl]\n",
    "\"\"\"\n",
    "def getRes(ref, cos, euc):\n",
    "    # res = [ref, my_cos, my_euc]\n",
    "    result = []\n",
    "    for my_res in [cos, euc]:\n",
    "        true_pos, false_neg = getDiagonal(my_res, ref)\n",
    "        false_pos = getFalsePos(my_res, ref)\n",
    "        p = getPrecision(true_pos, false_pos)\n",
    "        r = getRecall(true_pos, false_neg)\n",
    "        f = getFMeasure(p,r)\n",
    "        result.append(p)\n",
    "        result.append(r)\n",
    "        result.append(f)\n",
    "    \n",
    "    return result\n",
    "\n",
    "\n",
    "all_results = []\n",
    "q_count = len(all_res)\n",
    "for q in range(q_count):\n",
    "    res = {}\n",
    "    res['query'] = q\n",
    "    \n",
    "    ref_sol = reference[q]\n",
    "    # TF-IDF results\n",
    "    tfidf_res = getRes(ref_sol,tfidf_r[q*2], tfidf_r[q*2 + 1])\n",
    "\n",
    "    res[\"tf_idf_cos_precision\"] = tfidf_res[0]\n",
    "    res[\"tf_idf_cos_recall\"] = tfidf_res[1]\n",
    "    res[\"tf_idf_cos_fmeasure\"] = tfidf_res[2]\n",
    "    res[\"tf_idf_eucl_precision\"] = tfidf_res[3]\n",
    "    res[\"tf_idf_eucl_recall\"] = tfidf_res[4]\n",
    "    res[\"tf_idf_eucl_fmeasure\"] = tfidf_res[5]\n",
    "    \n",
    "     # Pure term frequency results\n",
    "    puretm_res = getRes(ref_sol, pure_r[q*2], pure_r[q*2+1])\n",
    "    res[\"puretm_cos_precision\"] = puretm_res[0]\n",
    "    res[\"puretm_cos_recall\"] = puretm_res[1]\n",
    "    res[\"puretm_cos_fmeasure\"] = puretm_res[2]\n",
    "    res[\"puretm_eucl_precision\"] = puretm_res[3]\n",
    "    res[\"puretm_eucl_recall\"] = puretm_res[4]\n",
    "    res[\"puretm_eucl_fmeasure\"] = puretm_res[5]\n",
    "    \n",
    "    # Boolean model results\n",
    "    bin_res = getRes(ref_sol, bin_r[q*2], bin_r[q*2+1])\n",
    "    res[\"binary_cos_precision\"] = bin_res[0]\n",
    "    res[\"binary_cos_recall\"] = bin_res[1]\n",
    "    res[\"binary_cos_fmeasure\"] = bin_res[2]\n",
    "    res[\"binary_eucl_precision\"] = bin_res[3]\n",
    "    res[\"binary_eucl_recall\"] = bin_res[4]\n",
    "    res[\"binary_eucl_fmeasure\"] = bin_res[5]\n",
    "\n",
    "    all_results.append(res)\n",
    "    \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Saving results to pandas data frame\n",
    "tab = pd.DataFrame(all_results)\n",
    "\n",
    "\"\"\"\n",
    "Saving results to task2.csv:\n",
    "    In each row are results for each query.\n",
    "\"\"\"\n",
    "tab.to_csv('task2.csv', sep=';')\n",
    "print(\"Saved: task2.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "display(tab.head())\n",
    "display(tab.info())\n",
    "print('Mean {columns}:')\n",
    "display(tab.mean())\n",
    "\n",
    "print('Max {columns}:')\n",
    "display(tab.max())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "max_q = tab.loc[(tab['tf_idf_cos_recall'] == 1)]\n",
    "max_q = max_q.drop(columns=['binary_eucl_fmeasure', 'binary_eucl_precision', 'binary_eucl_fmeasure'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "display(max_q)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "all_results[32] # Check on 1.0 value on recall\n",
    "print(reference[32])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(tfidf_r[32*2]) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#recall is 1:\n",
    "#true_positive: is 4\n",
    "#false negative is: 0\n",
    "# data looks ok\n",
    "print(getRes(reference[32], tfidf_r[32*2], tfidf_r[32*2+1]))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.9.13 64-bit (windows store)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.13"
  },
  "vscode": {
   "interpreter": {
    "hash": "9da297d614bb2667dfb21fadcf07f5f64679004c9ae9ad9a1b5a03e6f7f19cbc"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
